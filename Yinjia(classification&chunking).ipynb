{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import string\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_name</th>\n",
       "      <th>content</th>\n",
       "      <th>recommended</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air-canada-rouge</td>\n",
       "      <td>Flew to Lisbon from Toronto July 27 2015, plan...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air-canada-rouge</td>\n",
       "      <td>We are a family of 5 who had booked a flight f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air-canada-rouge</td>\n",
       "      <td>I checked our family of 6 in online before we ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air-canada-rouge</td>\n",
       "      <td>It was a 12 hour flight from Vancouver to Osak...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air-canada-rouge</td>\n",
       "      <td>Done all necessary procedure to make sure my g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       airline_name                                            content  \\\n",
       "0  air-canada-rouge  Flew to Lisbon from Toronto July 27 2015, plan...   \n",
       "1  air-canada-rouge  We are a family of 5 who had booked a flight f...   \n",
       "2  air-canada-rouge  I checked our family of 6 in online before we ...   \n",
       "3  air-canada-rouge  It was a 12 hour flight from Vancouver to Osak...   \n",
       "4  air-canada-rouge  Done all necessary procedure to make sure my g...   \n",
       "\n",
       "   recommended  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('/Users/liuyinjia/desktop/project1/airline review.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>airline_name</th>\n",
       "      <th>recommended</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">air-canada-rouge</th>\n",
       "      <th>0</th>\n",
       "      <td>608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">british-airways</th>\n",
       "      <th>0</th>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">united-airlines</th>\n",
       "      <th>0</th>\n",
       "      <td>598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              content\n",
       "airline_name     recommended         \n",
       "air-canada-rouge 0                608\n",
       "                 1                 95\n",
       "british-airways  0                364\n",
       "                 1                491\n",
       "united-airlines  0                598\n",
       "                 1                205"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['airline_name','recommended']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>recommended</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>airline_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>air-canada-rouge</th>\n",
       "      <td>703</td>\n",
       "      <td>703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>british-airways</th>\n",
       "      <td>855</td>\n",
       "      <td>855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>united-airlines</th>\n",
       "      <td>803</td>\n",
       "      <td>803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  content  recommended\n",
       "airline_name                          \n",
       "air-canada-rouge      703          703\n",
       "british-airways       855          855\n",
       "united-airlines       803          803"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['airline_name']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.loc['air-canada-rouge',['content','recommended']]\n",
    "df1=df.loc[df['airline_name']=='air-canada-rouge', ['content','recommended']]\n",
    "df2=df.loc[df['airline_name']=='british-airways', ['content','recommended']]\n",
    "df3=df.loc[df['airline_name']=='united-airlines', ['content','recommended']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>recommended</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Flew to Lisbon from Toronto July 27 2015, plan...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We are a family of 5 who had booked a flight f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I checked our family of 6 in online before we ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It was a 12 hour flight from Vancouver to Osak...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Done all necessary procedure to make sure my g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  recommended\n",
       "0  Flew to Lisbon from Toronto July 27 2015, plan...            0\n",
       "1  We are a family of 5 who had booked a flight f...            0\n",
       "2  I checked our family of 6 in online before we ...            0\n",
       "3  It was a 12 hour flight from Vancouver to Osak...            0\n",
       "4  Done all necessary procedure to make sure my g...            0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst1=df1.values.tolist()#a list of lists\n",
    "lst2=df2.values.tolist()\n",
    "lst3=df3.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[\"Flew to Lisbon from Toronto July 27 2015, plane was a older model, no entertainment system. We had to download an app on the iPad or if you don't have a iPad the airline rents them for $10. Movies are mostly older ones, which I was shocked to see, since I've flown overseas many times. The leg room seems tight compared to other overseas flights I've taken. Crew were very nice. I'm Canadian, and very disappointed in my countries main airliner. Long ways to go to be a premium airline.\", 0], ['We are a family of 5 who had booked a flight from Montreal to Athens with Aegean Airlines on July 26, 2015. It turned out it was Air Canada Rouge, flight AC 1902. The experience was mostly poor. The airplane was a 767-300 with tight legroom and no entertainment monitor displays. This was a big surprise for a transatlantic flight. When I did the web check-in on aircanada.com, it showed that the airplane had individual displays. The crew said you could download the application on an android or apple smartphone or rent an Ipad for $10. Of course we do not have such a device for each member of the family and paying for such a basic service item was out of the question. The Wifi was slow and the entertainment server would show busy many times when we tried to connect with the smartphone. The food was below average but the washrooms were kept in good condition during the flight. The only positive was the crew. They did all they could to help with questions and queries. I am not impressed with Air Canada Rouge. The quality of service is much lower than with Air Transat which we used to travel to Spain, Portugal, and France.', 0]]\n"
     ]
    }
   ],
   "source": [
    "print(lst1[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_canada_rouge=[(i[0],i[1]) for i in lst1]#a list of tuples\n",
    "british_airways=[(i[0],i[1]) for i in lst2]\n",
    "united_airlines=[(i[0],i[1]) for i in lst3]\n",
    "air1=[(nltk.word_tokenize(x),y) for x,y in air_canada_rouge]#air1 is a list of tuples,within tuple ,first item is a list of words for each review \n",
    "air2=[(nltk.word_tokenize(x),y) for x,y in british_airways]\n",
    "air3=[(nltk.word_tokenize(x),y) for x,y in united_airlines]\n",
    "air1_reviews=[ t[0] for t in air_canada_rouge ]#a list of text(reviews)\n",
    "air2_reviews=[ t[0] for t in british_airways ]\n",
    "air3_reviews=[ t[0] for t in united_airlines ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['Flew', 'to', 'Lisbon', 'from', 'Toronto', 'July', '27', '2015', ',', 'plane', 'was', 'a', 'older', 'model', ',', 'no', 'entertainment', 'system', '.', 'We', 'had', 'to', 'download', 'an', 'app', 'on', 'the', 'iPad', 'or', 'if', 'you', 'do', \"n't\", 'have', 'a', 'iPad', 'the', 'airline', 'rents', 'them', 'for', '$', '10', '.', 'Movies', 'are', 'mostly', 'older', 'ones', ',', 'which', 'I', 'was', 'shocked', 'to', 'see', ',', 'since', 'I', \"'ve\", 'flown', 'overseas', 'many', 'times', '.', 'The', 'leg', 'room', 'seems', 'tight', 'compared', 'to', 'other', 'overseas', 'flights', 'I', \"'ve\", 'taken', '.', 'Crew', 'were', 'very', 'nice', '.', 'I', \"'m\", 'Canadian', ',', 'and', 'very', 'disappointed', 'in', 'my', 'countries', 'main', 'airliner', '.', 'Long', 'ways', 'to', 'go', 'to', 'be', 'a', 'premium', 'airline', '.'], 0), (['We', 'are', 'a', 'family', 'of', '5', 'who', 'had', 'booked', 'a', 'flight', 'from', 'Montreal', 'to', 'Athens', 'with', 'Aegean', 'Airlines', 'on', 'July', '26', ',', '2015', '.', 'It', 'turned', 'out', 'it', 'was', 'Air', 'Canada', 'Rouge', ',', 'flight', 'AC', '1902', '.', 'The', 'experience', 'was', 'mostly', 'poor', '.', 'The', 'airplane', 'was', 'a', '767-300', 'with', 'tight', 'legroom', 'and', 'no', 'entertainment', 'monitor', 'displays', '.', 'This', 'was', 'a', 'big', 'surprise', 'for', 'a', 'transatlantic', 'flight', '.', 'When', 'I', 'did', 'the', 'web', 'check-in', 'on', 'aircanada.com', ',', 'it', 'showed', 'that', 'the', 'airplane', 'had', 'individual', 'displays', '.', 'The', 'crew', 'said', 'you', 'could', 'download', 'the', 'application', 'on', 'an', 'android', 'or', 'apple', 'smartphone', 'or', 'rent', 'an', 'Ipad', 'for', '$', '10', '.', 'Of', 'course', 'we', 'do', 'not', 'have', 'such', 'a', 'device', 'for', 'each', 'member', 'of', 'the', 'family', 'and', 'paying', 'for', 'such', 'a', 'basic', 'service', 'item', 'was', 'out', 'of', 'the', 'question', '.', 'The', 'Wifi', 'was', 'slow', 'and', 'the', 'entertainment', 'server', 'would', 'show', 'busy', 'many', 'times', 'when', 'we', 'tried', 'to', 'connect', 'with', 'the', 'smartphone', '.', 'The', 'food', 'was', 'below', 'average', 'but', 'the', 'washrooms', 'were', 'kept', 'in', 'good', 'condition', 'during', 'the', 'flight', '.', 'The', 'only', 'positive', 'was', 'the', 'crew', '.', 'They', 'did', 'all', 'they', 'could', 'to', 'help', 'with', 'questions', 'and', 'queries', '.', 'I', 'am', 'not', 'impressed', 'with', 'Air', 'Canada', 'Rouge', '.', 'The', 'quality', 'of', 'service', 'is', 'much', 'lower', 'than', 'with', 'Air', 'Transat', 'which', 'we', 'used', 'to', 'travel', 'to', 'Spain', ',', 'Portugal', ',', 'and', 'France', '.'], 0)]\n"
     ]
    }
   ],
   "source": [
    "print(air1[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use most common words as feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get review words without stop words and punctuations for each airline\n",
    "#input:a list of reviews \n",
    "#output:a list of words\n",
    "stop_words=stopwords.words(\"english\")\n",
    "def get_review_words(review):\n",
    "    review_words=[]\n",
    "    for w in review:\n",
    "        review_words.extend(w[0])\n",
    "    review_words=[w for w in review_words if not w.lower() in stop_words and not w in string.punctuation and w.isalpha() ]\n",
    "    return review_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_freq_air1=nltk.FreqDist(get_review_words(air1)).most_common()[:100]\n",
    "most_freq_air2=nltk.FreqDist(get_review_words(air2)).most_common()[:100]\n",
    "most_freq_air3=nltk.FreqDist(get_review_words(air3)).most_common()[:100]\n",
    "most_freq_air1=[w[0] for w in most_freq_air1]\n",
    "most_freq_air2=[w[0] for w in most_freq_air2]\n",
    "most_freq_air3=[w[0] for w in most_freq_air3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['flight', 'Rouge', 'Air', 'Canada', 'seat', 'seats', 'AC', 'entertainment', 'Toronto', 'service', 'would', 'fly', 'back', 'room', 'time', 'airline', 'flights', 'plane', 'could', 'leg', 'one', 'get', 'even', 'food', 'hours', 'front', 'class', 'never', 'experience', 'crew', 'return', 'us', 'flew', 'good', 'uncomfortable', 'like', 'staff', 'flying', 'business', 'hour', 'way', 'first', 'trip', 'economy', 'attendants', 'passengers', 'cramped', 'booked', 'got', 'people', 'regular', 'system', 'knees', 'rouge', 'movies', 'use', 'last', 'iPad', 'worst', 'much', 'Vegas', 'cabin', 'space', 'paid', 'seating', 'old', 'app', 'Vancouver', 'little', 'long', 'inflight', 'new', 'pay', 'Flight', 'told', 'extra', 'ever', 'legroom', 'years', 'Flew', 'another', 'many', 'Premium', 'better', 'aircraft', 'travel', 'know', 'also', 'comfortable', 'legs', 'cost', 'price', 'say', 'bad', 'flown', 'poor', 'full', 'take', 'unless', 'made']\n",
      "['flight', 'BA', 'good', 'seat', 'service', 'seats', 'crew', 'food', 'time', 'cabin', 'Club', 'staff', 'class', 'would', 'return', 'one', 'flights', 'LHR', 'get', 'back', 'economy', 'excellent', 'Heathrow', 'could', 'business', 'comfortable', 'lounge', 'passengers', 'experience', 'plane', 'better', 'London', 'fly', 'new', 'hours', 'meal', 'great', 'us', 'World', 'aircraft', 'much', 'really', 'first', 'old', 'even', 'nice', 'served', 'entertainment', 'drinks', 'Food', 'like', 'hour', 'friendly', 'choice', 'boarding', 'First', 'poor', 'got', 'minutes', 'well', 'leg', 'long', 'way', 'British', 'Europe', 'Flight', 'Business', 'check', 'airline', 'late', 'full', 'trip', 'small', 'breakfast', 'space', 'room', 'little', 'Airways', 'extra', 'offered', 'also', 'Flew', 'quite', 'due', 'selection', 'IFE', 'flying', 'drink', 'Gatwick', 'board', 'flew', 'made', 'system', 'money', 'last', 'next', 'airlines', 'bit', 'Class', 'two']\n",
      "['flight', 'United', 'service', 'time', 'plane', 'hours', 'flights', 'us', 'would', 'get', 'seat', 'one', 'seats', 'hour', 'airline', 'food', 'could', 'back', 'crew', 'delayed', 'fly', 'told', 'staff', 'first', 'even', 'good', 'airport', 'class', 'UA', 'minutes', 'next', 'got', 'never', 'gate', 'due', 'passengers', 'customer', 'trip', 'experience', 'flying', 'late', 'another', 'last', 'cancelled', 'Chicago', 'Newark', 'entertainment', 'people', 'day', 'arrived', 'return', 'connecting', 'two', 'flew', 'Houston', 'Airlines', 'aircraft', 'like', 'attendants', 'delay', 'way', 'Flight', 'business', 'airlines', 'made', 'boarding', 'luggage', 'asked', 'make', 'booked', 'leg', 'pay', 'economy', 'go', 'long', 'travel', 'much', 'new', 'First', 'cabin', 'connection', 'later', 'friendly', 'take', 'also', 'old', 'left', 'going', 'attendant', 'offered', 'comfortable', 'board', 'better', 'bad', 'took', 'check', 'bags', 'wait', 'line', 'went']\n"
     ]
    }
   ],
   "source": [
    "print(most_freq_air1)\n",
    "print(most_freq_air2)\n",
    "print(most_freq_air3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the most common words feature extractor\n",
    "def most_common_features(review,most_freq_words):\n",
    "    features={} \n",
    "    for w in most_freq_words:\n",
    "        features[w] = (w in review) \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[({'flight': True, 'Rouge': True, 'Air': True, 'Canada': True, 'seat': True, 'seats': True, 'AC': False, 'entertainment': True, 'Toronto': True, 'service': True, 'would': True, 'fly': True, 'back': False, 'room': False, 'time': False, 'airline': False, 'flights': True, 'plane': True, 'could': False, 'leg': False, 'one': True, 'get': True, 'even': False, 'food': True, 'hours': True, 'front': False, 'class': True, 'never': False, 'experience': False, 'crew': True, 'return': True, 'us': False, 'flew': False, 'good': False, 'uncomfortable': False, 'like': True, 'staff': False, 'flying': True, 'business': True, 'hour': True, 'way': False, 'first': False, 'trip': True, 'economy': True, 'attendants': False, 'passengers': False, 'cramped': False, 'booked': False, 'got': False, 'people': False, 'regular': True, 'system': False, 'knees': False, 'rouge': False, 'movies': True, 'use': False, 'last': False, 'iPad': True, 'worst': False, 'much': True, 'Vegas': True, 'cabin': False, 'space': False, 'paid': False, 'seating': True, 'old': False, 'app': False, 'Vancouver': False, 'little': False, 'long': False, 'inflight': False, 'new': False, 'pay': True, 'Flight': True, 'told': False, 'extra': True, 'ever': False, 'legroom': True, 'years': False, 'Flew': True, 'another': False, 'many': False, 'Premium': True, 'better': True, 'aircraft': False, 'travel': False, 'know': False, 'also': False, 'comfortable': True, 'legs': False, 'cost': False, 'price': False, 'say': True, 'bad': False, 'flown': False, 'poor': False, 'full': False, 'take': True, 'unless': True, 'made': True}, 1), ({'flight': True, 'Rouge': True, 'Air': True, 'Canada': True, 'seat': True, 'seats': False, 'AC': False, 'entertainment': True, 'Toronto': True, 'service': False, 'would': True, 'fly': True, 'back': True, 'room': True, 'time': True, 'airline': True, 'flights': True, 'plane': False, 'could': False, 'leg': True, 'one': False, 'get': True, 'even': False, 'food': False, 'hours': False, 'front': True, 'class': False, 'never': True, 'experience': False, 'crew': False, 'return': False, 'us': False, 'flew': True, 'good': False, 'uncomfortable': False, 'like': True, 'staff': False, 'flying': False, 'business': True, 'hour': True, 'way': True, 'first': False, 'trip': False, 'economy': True, 'attendants': False, 'passengers': False, 'cramped': False, 'booked': False, 'got': False, 'people': False, 'regular': True, 'system': False, 'knees': False, 'rouge': False, 'movies': True, 'use': False, 'last': False, 'iPad': False, 'worst': False, 'much': False, 'Vegas': False, 'cabin': False, 'space': False, 'paid': False, 'seating': False, 'old': False, 'app': True, 'Vancouver': False, 'little': False, 'long': True, 'inflight': False, 'new': False, 'pay': True, 'Flight': False, 'told': False, 'extra': False, 'ever': False, 'legroom': False, 'years': True, 'Flew': False, 'another': False, 'many': False, 'Premium': False, 'better': False, 'aircraft': False, 'travel': False, 'know': False, 'also': False, 'comfortable': False, 'legs': False, 'cost': False, 'price': False, 'say': False, 'bad': False, 'flown': False, 'poor': False, 'full': True, 'take': True, 'unless': False, 'made': False}, 0)]\n"
     ]
    }
   ],
   "source": [
    "# now create the most common words feature set\n",
    "featureset1=[(most_common_features(d,most_freq_air1),c) for (d,c) in air1]\n",
    "featureset2=[(most_common_features(d,most_freq_air2),c) for (d,c) in air2]\n",
    "featureset3=[(most_common_features(d,most_freq_air3),c) for (d,c) in air3]\n",
    "random.shuffle(featureset1)\n",
    "random.shuffle(featureset2)\n",
    "random.shuffle(featureset3)\n",
    "print(featureset1[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "562\n",
      "141\n"
     ]
    }
   ],
   "source": [
    "# divide train and test set\n",
    "training_set1=featureset1[:int(len(featureset1)*0.8)] \n",
    "testing_set1=featureset1[int(len(featureset1)*0.8):]\n",
    "print(len(training_set1))\n",
    "print(len(testing_set1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684\n",
      "171\n"
     ]
    }
   ],
   "source": [
    "training_set2=featureset2[:int(len(featureset2)*0.8)] \n",
    "testing_set2=featureset2[int(len(featureset2)*0.8):]\n",
    "print(len(training_set2))\n",
    "print(len(testing_set2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "642\n",
      "161\n"
     ]
    }
   ],
   "source": [
    "training_set3=featureset3[:int(len(featureset3)*0.8)] \n",
    "testing_set3=featureset3[int(len(featureset3)*0.8):]\n",
    "print(len(training_set3))\n",
    "print(len(testing_set3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9148936170212766\n",
      "Most Informative Features\n",
      "                   knees = True                0 : 1      =      7.6 : 1.0\n",
      "           uncomfortable = True                0 : 1      =      6.8 : 1.0\n",
      "                   never = True                0 : 1      =      5.3 : 1.0\n",
      "                    good = True                1 : 0      =      3.3 : 1.0\n",
      "                  better = True                1 : 0      =      3.1 : 1.0\n",
      "                   front = True                0 : 1      =      3.1 : 1.0\n",
      "                 Premium = True                1 : 0      =      3.0 : 1.0\n",
      "                    cost = True                0 : 1      =      3.0 : 1.0\n",
      "                    ever = True                0 : 1      =      2.8 : 1.0\n",
      "             comfortable = True                1 : 0      =      2.8 : 1.0\n",
      "                    food = True                1 : 0      =      2.7 : 1.0\n",
      "                   cabin = True                1 : 0      =      2.6 : 1.0\n",
      "                   hours = True                0 : 1      =      2.6 : 1.0\n",
      "                    even = True                0 : 1      =      2.4 : 1.0\n",
      "                     bad = True                1 : 0      =      2.2 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "classifier=nltk.NaiveBayesClassifier.train(training_set1)\n",
    "print(nltk.classify.accuracy(classifier,testing_set1)) \n",
    "print(classifier.show_most_informative_features(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7777777777777778\n",
      "Most Informative Features\n",
      "               excellent = True                1 : 0      =      4.2 : 1.0\n",
      "             comfortable = True                1 : 0      =      3.3 : 1.0\n",
      "                    nice = True                1 : 0      =      2.8 : 1.0\n",
      "                     bit = True                1 : 0      =      2.5 : 1.0\n",
      "                airlines = True                0 : 1      =      2.3 : 1.0\n",
      "                friendly = True                1 : 0      =      2.3 : 1.0\n",
      "                    good = True                1 : 0      =      2.3 : 1.0\n",
      "                 British = True                0 : 1      =      2.3 : 1.0\n",
      "                 airline = True                0 : 1      =      2.3 : 1.0\n",
      "                 Airways = True                0 : 1      =      2.3 : 1.0\n",
      "               selection = True                1 : 0      =      2.2 : 1.0\n",
      "                    hour = True                0 : 1      =      2.1 : 1.0\n",
      "                    full = True                1 : 0      =      2.1 : 1.0\n",
      "                   money = True                0 : 1      =      2.0 : 1.0\n",
      "                   plane = True                0 : 1      =      2.0 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "classifier=nltk.NaiveBayesClassifier.train(training_set2)\n",
    "print(nltk.classify.accuracy(classifier,testing_set2)) \n",
    "print(classifier.show_most_informative_features(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7701863354037267\n",
      "Most Informative Features\n",
      "               cancelled = True                0 : 1      =      8.6 : 1.0\n",
      "                    wait = True                0 : 1      =      6.9 : 1.0\n",
      "                customer = True                0 : 1      =      6.1 : 1.0\n",
      "             comfortable = True                1 : 0      =      5.7 : 1.0\n",
      "                    told = True                0 : 1      =      5.4 : 1.0\n",
      "                friendly = True                1 : 0      =      5.4 : 1.0\n",
      "                   later = True                0 : 1      =      4.1 : 1.0\n",
      "                 luggage = True                0 : 1      =      4.0 : 1.0\n",
      "                    took = True                0 : 1      =      3.4 : 1.0\n",
      "                 another = True                0 : 1      =      3.4 : 1.0\n",
      "                   asked = True                0 : 1      =      3.4 : 1.0\n",
      "                    good = True                1 : 0      =      3.2 : 1.0\n",
      "              connecting = True                0 : 1      =      3.1 : 1.0\n",
      "                 airport = True                0 : 1      =      3.0 : 1.0\n",
      "                  booked = True                0 : 1      =      3.0 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "classifier=nltk.NaiveBayesClassifier.train(training_set3)\n",
    "print(nltk.classify.accuracy(classifier,testing_set3)) \n",
    "print(classifier.show_most_informative_features(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use least common words as feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "least_freq_air1=nltk.FreqDist(get_review_words(air1)).most_common()[-100:]\n",
    "least_freq_air2=nltk.FreqDist(get_review_words(air2)).most_common()[-100:]\n",
    "least_freq_air3=nltk.FreqDist(get_review_words(air3)).most_common()[-100:]\n",
    "least_freq_air1=[w[0] for w in least_freq_air1]\n",
    "least_freq_air2=[w[0] for w in least_freq_air2]\n",
    "least_freq_air3=[w[0] for w in least_freq_air3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the least common words feature extractor\n",
    "def least_common_features(review,least_freq_words):\n",
    "    features={} \n",
    "    for w in least_freq_words:\n",
    "        features[w] = (w in review) \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now create the least common words feature set\n",
    "featureset1=[(least_common_features(d,most_freq_air1),c) for (d,c) in air1]\n",
    "featureset2=[(least_common_features(d,most_freq_air2),c) for (d,c) in air2]\n",
    "featureset3=[(least_common_features(d,most_freq_air3),c) for (d,c) in air3]\n",
    "random.shuffle(featureset1)\n",
    "random.shuffle(featureset2)\n",
    "random.shuffle(featureset3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide train and test set\n",
    "training_set1=featureset1[:int(len(featureset1)*0.8)] \n",
    "testing_set1=featureset1[int(len(featureset1)*0.8):]\n",
    "training_set2=featureset2[:int(len(featureset2)*0.8)] \n",
    "testing_set2=featureset2[int(len(featureset2)*0.8):]\n",
    "training_set3=featureset3[:int(len(featureset3)*0.8)] \n",
    "testing_set3=featureset3[int(len(featureset3)*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8581560283687943\n",
      "Most Informative Features\n",
      "              pleasantly = True                1 : 0      =     28.2 : 1.0\n",
      "               attentive = True                1 : 0      =     18.4 : 1.0\n",
      "                    easy = True                1 : 0      =     14.9 : 1.0\n",
      "             appreciated = True                1 : 0      =     14.3 : 1.0\n",
      "               satisfied = True                1 : 0      =     14.3 : 1.0\n",
      "                   films = True                1 : 0      =     14.3 : 1.0\n",
      "                     Oct = True                1 : 0      =     14.3 : 1.0\n",
      "                     HNL = True                1 : 0      =     13.5 : 1.0\n",
      "                   tasty = True                1 : 0      =     13.5 : 1.0\n",
      "           uncomfortable = True                0 : 1      =     12.7 : 1.0\n",
      "                   clean = True                1 : 0      =     12.6 : 1.0\n",
      "               complaint = True                1 : 0      =     11.6 : 1.0\n",
      "                priority = True                1 : 0      =     11.4 : 1.0\n",
      "             connections = True                1 : 0      =     11.1 : 1.0\n",
      "              maintained = True                1 : 0      =     11.1 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "classifier=nltk.NaiveBayesClassifier.train(training_set1)\n",
    "print(nltk.classify.accuracy(classifier,testing_set1)) \n",
    "print(classifier.show_most_informative_features(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7602339181286549\n",
      "Most Informative Features\n",
      "               excellent = True                1 : 0      =      4.4 : 1.0\n",
      "             comfortable = True                1 : 0      =      3.5 : 1.0\n",
      "                    full = True                1 : 0      =      3.0 : 1.0\n",
      "                     bit = True                1 : 0      =      2.7 : 1.0\n",
      "                friendly = True                1 : 0      =      2.5 : 1.0\n",
      "                 Airways = True                0 : 1      =      2.4 : 1.0\n",
      "                 British = True                0 : 1      =      2.3 : 1.0\n",
      "                    good = True                1 : 0      =      2.3 : 1.0\n",
      "               selection = True                1 : 0      =      2.3 : 1.0\n",
      "                 airline = True                0 : 1      =      2.2 : 1.0\n",
      "                airlines = True                0 : 1      =      2.1 : 1.0\n",
      "                    nice = True                1 : 0      =      2.1 : 1.0\n",
      "                   could = True                0 : 1      =      2.0 : 1.0\n",
      "                     get = True                0 : 1      =      1.9 : 1.0\n",
      "                    poor = True                0 : 1      =      1.9 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "classifier=nltk.NaiveBayesClassifier.train(training_set2)\n",
    "print(nltk.classify.accuracy(classifier,testing_set2)) \n",
    "print(classifier.show_most_informative_features(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7453416149068323\n",
      "Most Informative Features\n",
      "               cancelled = True                0 : 1      =      8.9 : 1.0\n",
      "                    told = True                0 : 1      =      6.7 : 1.0\n",
      "             comfortable = True                1 : 0      =      6.3 : 1.0\n",
      "                    wait = True                0 : 1      =      5.9 : 1.0\n",
      "                friendly = True                1 : 0      =      5.2 : 1.0\n",
      "                customer = True                0 : 1      =      5.1 : 1.0\n",
      "                   never = True                0 : 1      =      4.4 : 1.0\n",
      "                   later = True                0 : 1      =      4.3 : 1.0\n",
      "                    took = True                0 : 1      =      4.2 : 1.0\n",
      "                 another = True                0 : 1      =      4.1 : 1.0\n",
      "              connecting = True                0 : 1      =      3.8 : 1.0\n",
      "                  booked = True                0 : 1      =      3.6 : 1.0\n",
      "                    line = True                0 : 1      =      3.3 : 1.0\n",
      "                    good = True                1 : 0      =      3.0 : 1.0\n",
      "                 luggage = True                0 : 1      =      2.8 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "classifier=nltk.NaiveBayesClassifier.train(training_set3)\n",
    "print(nltk.classify.accuracy(classifier,testing_set3)) \n",
    "print(classifier.show_most_informative_features(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use most common JJ as feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try second feature,use most common JJ\n",
    "pos1=[nltk.pos_tag(x) for x,y in air1]\n",
    "#pos2=[nltk.pos_tag(x) for x,y in air2]\n",
    "#pos3=[nltk.pos_tag(x) for x,y in air3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos2=[nltk.pos_tag(x) for x,y in air2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos3=[nltk.pos_tag(x) for x,y in air3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get most common 100 JJ words\n",
    "def get_most_common_JJ(pos):\n",
    "    jjlist=[]\n",
    "    for i in pos:\n",
    "        jjs=[x[0].lower() for x in i if 'JJ' in x[1] and len(x[0])>=3 and x[0].isalpha()]\n",
    "        jjlist+=jjs\n",
    "    jjfrequency=nltk.FreqDist(jjlist)\n",
    "    freqjj=[x for x,y in jjfrequency.most_common(100)]\n",
    "    return freqjj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_JJ_air1=get_most_common_JJ(pos1)\n",
    "most_common_JJ_air2=get_most_common_JJ(pos2)\n",
    "most_common_JJ_air3=get_most_common_JJ(pos3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['other', 'good', 'same', 'uncomfortable', 'first', 'more', 'regular', 'last', 'worst', 'old', 'new', 'many', 'little', 'inflight', 'extra', 'comfortable', 'own', 'only', 'full', 'bad', 'poor', 'terrible', 'small', 'long', 'much', 'better', 'leg', 'young', 'able', 'next', 'free', 'great', 'less', 'most', 'available', 'least', 'cramped', 'friendly', 'few', 'due', 'nice', 'sure', 'low', 'fine', 'horrible', 'premium', 'tight', 'worse', 'best', 'awful', 'such', 'entire', 'pleasant', 'late', 'middle', 'short', 'rouge', 'overhead', 'clean', 'overall', 'enough', 'limited', 'big', 'cheap', 'several', 'normal', 'high', 'negative', 'different', 'tall', 'disappointed', 'hard', 'ridiculous', 'possible', 'happy', 'whole', 'helpful', 'attentive', 'average', 'previous', 'narrow', 'hot', 'professional', 'second', 'excellent', 'cold', 'inexperienced', 'past', 'main', 'personal', 'loyal', 'expensive', 'red', 'real', 'smaller', 'disappointing', 'direct', 'future', 'frequent', 'impossible']\n"
     ]
    }
   ],
   "source": [
    "#try this function\n",
    "print(most_common_JJ_air1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the most common JJ feature extractor \n",
    "def most_JJ_feature(text,most_common_JJ): \n",
    "    res={}\n",
    "    for i in most_common_JJ:\n",
    "        res[i]=i in set([x.lower() for x in text])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[({'other': True, 'good': True, 'same': False, 'uncomfortable': False, 'first': False, 'more': False, 'regular': False, 'last': False, 'worst': False, 'old': False, 'new': False, 'many': False, 'little': False, 'inflight': False, 'extra': False, 'comfortable': False, 'own': False, 'only': False, 'full': False, 'bad': False, 'poor': False, 'terrible': False, 'small': False, 'long': True, 'much': False, 'better': False, 'leg': False, 'young': False, 'able': False, 'next': False, 'free': False, 'great': False, 'less': False, 'most': False, 'available': False, 'least': False, 'cramped': False, 'friendly': False, 'few': False, 'due': True, 'nice': False, 'sure': False, 'low': False, 'fine': False, 'horrible': False, 'premium': False, 'tight': False, 'worse': False, 'best': False, 'awful': False, 'such': False, 'entire': False, 'pleasant': False, 'late': False, 'middle': False, 'short': False, 'rouge': False, 'overhead': False, 'clean': False, 'overall': True, 'enough': False, 'limited': False, 'big': False, 'cheap': False, 'several': False, 'normal': False, 'high': False, 'negative': True, 'different': False, 'tall': False, 'disappointed': False, 'hard': False, 'ridiculous': False, 'possible': False, 'happy': False, 'whole': False, 'helpful': False, 'attentive': False, 'average': True, 'previous': False, 'narrow': False, 'hot': False, 'professional': True, 'second': False, 'excellent': False, 'cold': False, 'inexperienced': False, 'past': False, 'main': False, 'personal': False, 'loyal': False, 'expensive': False, 'red': False, 'real': False, 'smaller': False, 'disappointing': False, 'direct': False, 'future': False, 'frequent': False, 'impossible': False}, 1), ({'other': True, 'good': True, 'same': False, 'uncomfortable': True, 'first': False, 'more': False, 'regular': True, 'last': False, 'worst': False, 'old': False, 'new': False, 'many': True, 'little': True, 'inflight': False, 'extra': False, 'comfortable': False, 'own': False, 'only': False, 'full': False, 'bad': False, 'poor': False, 'terrible': False, 'small': False, 'long': False, 'much': False, 'better': False, 'leg': True, 'young': False, 'able': False, 'next': False, 'free': False, 'great': False, 'less': False, 'most': False, 'available': True, 'least': False, 'cramped': False, 'friendly': False, 'few': False, 'due': False, 'nice': False, 'sure': False, 'low': False, 'fine': False, 'horrible': False, 'premium': False, 'tight': False, 'worse': False, 'best': False, 'awful': False, 'such': False, 'entire': False, 'pleasant': False, 'late': False, 'middle': False, 'short': False, 'rouge': True, 'overhead': False, 'clean': False, 'overall': False, 'enough': False, 'limited': False, 'big': False, 'cheap': False, 'several': False, 'normal': False, 'high': False, 'negative': False, 'different': False, 'tall': False, 'disappointed': False, 'hard': False, 'ridiculous': False, 'possible': False, 'happy': False, 'whole': False, 'helpful': False, 'attentive': False, 'average': True, 'previous': True, 'narrow': False, 'hot': False, 'professional': False, 'second': False, 'excellent': False, 'cold': False, 'inexperienced': False, 'past': False, 'main': False, 'personal': False, 'loyal': False, 'expensive': False, 'red': False, 'real': False, 'smaller': False, 'disappointing': False, 'direct': False, 'future': False, 'frequent': False, 'impossible': False}, 0)]\n"
     ]
    }
   ],
   "source": [
    "#  most common JJ feature set\n",
    "featureset1=[(most_JJ_feature(d,most_common_JJ_air1),c) for d, c in air1]\n",
    "random.shuffle(featureset1)\n",
    "print(featureset1[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureset2=[(most_JJ_feature(d,most_common_JJ_air2),c) for d, c in air2]\n",
    "random.shuffle(featureset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureset3=[(most_JJ_feature(d,most_common_JJ_air3),c) for d, c in air3]\n",
    "random.shuffle(featureset3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "562\n",
      "141\n"
     ]
    }
   ],
   "source": [
    "# divide train and test set for air 1\n",
    "training_set1=featureset1[:int(len(featureset1)*0.8)] \n",
    "testing_set1=featureset1[int(len(featureset1)*0.8):]\n",
    "print(len(training_set1))\n",
    "print(len(testing_set1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684\n",
      "171\n"
     ]
    }
   ],
   "source": [
    "# divide train and test set for air 2\n",
    "training_set2=featureset2[:int(len(featureset2)*0.8)] \n",
    "testing_set2=featureset2[int(len(featureset2)*0.8):]\n",
    "print(len(training_set2))\n",
    "print(len(testing_set2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "642\n",
      "161\n"
     ]
    }
   ],
   "source": [
    "# divide train and test set for air 3\n",
    "training_set3=featureset3[:int(len(featureset3)*0.8)] \n",
    "testing_set3=featureset3[int(len(featureset3)*0.8):]\n",
    "print(len(training_set3))\n",
    "print(len(testing_set3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9078014184397163\n",
      "Most Informative Features\n",
      "               attentive = True                1 : 0      =     20.4 : 1.0\n",
      "                   clean = True                1 : 0      =     13.8 : 1.0\n",
      "            professional = True                1 : 0      =     13.2 : 1.0\n",
      "           uncomfortable = True                0 : 1      =     11.1 : 1.0\n",
      "               excellent = True                1 : 0      =      9.7 : 1.0\n",
      "                   great = True                1 : 0      =      6.3 : 1.0\n",
      "                negative = True                1 : 0      =      6.3 : 1.0\n",
      "                    nice = True                1 : 0      =      6.0 : 1.0\n",
      "                    fine = True                1 : 0      =      5.0 : 1.0\n",
      "                pleasant = True                1 : 0      =      4.4 : 1.0\n",
      "                 helpful = True                1 : 0      =      4.3 : 1.0\n",
      "                   least = True                0 : 1      =      4.3 : 1.0\n",
      "                 overall = True                1 : 0      =      4.1 : 1.0\n",
      "                     hot = True                1 : 0      =      4.0 : 1.0\n",
      "                  better = True                1 : 0      =      3.7 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#train mode2 and test accuracy for air 1\n",
    "classifier=nltk.NaiveBayesClassifier.train(training_set1)\n",
    "print(nltk.classify.accuracy(classifier,testing_set1)) \n",
    "print(classifier.show_most_informative_features(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8362573099415205\n",
      "Most Informative Features\n",
      "                   tasty = True                1 : 0      =      8.7 : 1.0\n",
      "                   awful = True                0 : 1      =      8.5 : 1.0\n",
      "                  smooth = True                1 : 0      =      7.3 : 1.0\n",
      "           uncomfortable = True                0 : 1      =      7.0 : 1.0\n",
      "                   worst = True                0 : 1      =      5.9 : 1.0\n",
      "                terrible = True                0 : 1      =      5.2 : 1.0\n",
      "                   quiet = True                1 : 0      =      5.0 : 1.0\n",
      "                   quick = True                1 : 0      =      5.0 : 1.0\n",
      "            disappointed = True                0 : 1      =      4.6 : 1.0\n",
      "               attentive = True                1 : 0      =      4.1 : 1.0\n",
      "               excellent = True                1 : 0      =      4.0 : 1.0\n",
      "             comfortable = True                1 : 0      =      3.5 : 1.0\n",
      "               efficient = True                1 : 0      =      3.2 : 1.0\n",
      "                inedible = True                0 : 1      =      3.1 : 1.0\n",
      "                possible = True                0 : 1      =      3.0 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#train mode2 and test accuracy for air 2\n",
    "classifier=nltk.NaiveBayesClassifier.train(training_set2)\n",
    "print(nltk.classify.accuracy(classifier,testing_set2)) \n",
    "print(classifier.show_most_informative_features(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8944099378881988\n",
      "Most Informative Features\n",
      "               attentive = True                1 : 0      =     22.3 : 1.0\n",
      "                   clean = True                1 : 0      =      9.0 : 1.0\n",
      "                   worst = True                0 : 1      =      7.9 : 1.0\n",
      "                   happy = True                1 : 0      =      7.5 : 1.0\n",
      "                terrible = True                0 : 1      =      6.7 : 1.0\n",
      "               efficient = True                1 : 0      =      6.0 : 1.0\n",
      "              mechanical = True                0 : 1      =      6.0 : 1.0\n",
      "             comfortable = True                1 : 0      =      5.3 : 1.0\n",
      "                friendly = True                1 : 0      =      5.2 : 1.0\n",
      "               excellent = True                1 : 0      =      5.0 : 1.0\n",
      "            professional = True                1 : 0      =      4.9 : 1.0\n",
      "                   great = True                1 : 0      =      4.8 : 1.0\n",
      "                   total = True                0 : 1      =      4.6 : 1.0\n",
      "                  decent = True                1 : 0      =      4.5 : 1.0\n",
      "                    rude = True                0 : 1      =      4.2 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#train mode2 and test accuracy for air 3\n",
    "classifier=nltk.NaiveBayesClassifier.train(training_set3)\n",
    "print(nltk.classify.accuracy(classifier,testing_set3)) \n",
    "print(classifier.show_most_informative_features(15))\n",
    "#terrible,rude,worst,wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use tfidf as feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try third feature tfidf\n",
    "def get_tfidf(reviews):\n",
    "    vectorizer=TfidfVectorizer()\n",
    "    tfidf=vectorizer.fit_transform(reviews)\n",
    "    #print(tfidf)\n",
    "    num_word=len(vectorizer.get_feature_names())\n",
    "    #print(num_word)\n",
    "    return (tfidf,num_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3776)\t0.09021594360255614\n",
      "  (0, 783)\t0.05279829316919587\n",
      "  (0, 2330)\t0.1018342813481112\n",
      "  (0, 5357)\t0.12823634250423224\n",
      "  (0, 3018)\t0.0932522791586014\n",
      "  (0, 465)\t0.2047527580532276\n",
      "  (0, 3084)\t0.14091126683934874\n",
      "  (0, 1398)\t0.19265710532138305\n",
      "  (0, 3301)\t0.04610499442208664\n",
      "  (0, 2608)\t0.037798447100231794\n",
      "  (0, 1655)\t0.11852848782547531\n",
      "  (0, 536)\t0.03148686372346608\n",
      "  (0, 1011)\t0.14670324173315477\n",
      "  (0, 3360)\t0.1081379591861498\n",
      "  (0, 5279)\t0.12095794301080486\n",
      "  (0, 5381)\t0.04692031735035017\n",
      "  (0, 1439)\t0.07932025905078384\n",
      "  (0, 4839)\t0.11771113395121839\n",
      "  (0, 2174)\t0.06606030048646408\n",
      "  (0, 3505)\t0.07517030849895028\n",
      "  (0, 1255)\t0.14670324173315477\n",
      "  (0, 4967)\t0.11057454146958971\n",
      "  (0, 4367)\t0.13062414055731988\n",
      "  (0, 4221)\t0.06577618833694553\n",
      "  (0, 2919)\t0.06890355090103549\n",
      "  :\t:\n",
      "  (702, 1010)\t0.1623001354495776\n",
      "  (702, 456)\t0.10557104933275101\n",
      "  (702, 2758)\t0.05598777487177516\n",
      "  (702, 5448)\t0.15763258463225346\n",
      "  (702, 2173)\t0.0462914582319547\n",
      "  (702, 3433)\t0.09491978962271835\n",
      "  (702, 2608)\t0.09326256415414703\n",
      "  (702, 536)\t0.1553791688973716\n",
      "  (702, 5381)\t0.057884773618029614\n",
      "  (702, 4221)\t0.08114693135835231\n",
      "  (702, 2919)\t0.08500510377206676\n",
      "  (702, 2183)\t0.1256311690813012\n",
      "  (702, 4913)\t0.09598201932518598\n",
      "  (702, 464)\t0.08386088743765721\n",
      "  (702, 2579)\t0.07977737198982263\n",
      "  (702, 4909)\t0.23174649810379153\n",
      "  (702, 531)\t0.06710733657611861\n",
      "  (702, 2396)\t0.124834046837737\n",
      "  (702, 5358)\t0.1967720670954259\n",
      "  (702, 5341)\t0.13706271719248717\n",
      "  (702, 3691)\t0.08824258869623387\n",
      "  (702, 5007)\t0.06944284646455988\n",
      "  (702, 2265)\t0.057792188258655015\n",
      "  (702, 4986)\t0.07648381133314484\n",
      "  (702, 2168)\t0.07977737198982263\n",
      "5533\n"
     ]
    }
   ],
   "source": [
    "tfidf1, num_word1 = get_tfidf(air1_reviews)#air1_reviews is a list of text(reviews)\n",
    "print(tfidf1)\n",
    "print(num_word1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf2, num_word2 = get_tfidf(air2_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf3, num_word3 = get_tfidf(air3_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the feature function\n",
    "def tfidf_feature(review_index,reviews,tfidf,num_word):\n",
    "    sum_tfidf=sum([tfidf[review_index,word_index] for word_index in range(0,num_word)])\n",
    "    length=len(nltk.word_tokenize(reviews[review_index]))\n",
    "#    return {'avg_tfidf':sum_tfidf/length,'length':length}\n",
    "    return {'avg_tfidf':round((sum_tfidf/length),2)}#round 2 digits for most informative using\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'avg_tfidf': 0.07}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#try feature function\n",
    "tfidf_feature(0,air1_reviews,tfidf1, num_word1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureset1=[]#take few minutes\n",
    "for review_index in range(0,702):\n",
    "    clas=air1[review_index][1]\n",
    "    feature=tfidf_feature(review_index,air1_reviews,tfidf1,num_word1)\n",
    "    featureset1.append((feature,clas))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(0.06865119778707979,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'avg_tfidf': 0.07}, 0),\n",
       " ({'avg_tfidf': 0.04}, 0),\n",
       " ({'avg_tfidf': 0.04}, 0),\n",
       " ({'avg_tfidf': 0.07}, 0),\n",
       " ({'avg_tfidf': 0.07}, 0),\n",
       " ({'avg_tfidf': 0.14}, 0),\n",
       " ({'avg_tfidf': 0.04}, 0),\n",
       " ({'avg_tfidf': 0.08}, 0),\n",
       " ({'avg_tfidf': 0.05}, 0),\n",
       " ({'avg_tfidf': 0.03}, 0)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featureset1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "561\n",
      "141\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(featureset1)\n",
    "# divide train and test set for air 1\n",
    "training_set1=featureset1[:int(len(featureset1)*0.8)] \n",
    "testing_set1=featureset1[int(len(featureset1)*0.8):]\n",
    "print(len(training_set1))\n",
    "print(len(testing_set1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8652482269503546\n",
      "Most Informative Features\n",
      "               avg_tfidf = 0.02                1 : 0      =      6.0 : 1.0\n",
      "               avg_tfidf = 0.11                0 : 1      =      2.1 : 1.0\n",
      "               avg_tfidf = 0.13                1 : 0      =      2.0 : 1.0\n",
      "               avg_tfidf = 0.12                1 : 0      =      2.0 : 1.0\n",
      "               avg_tfidf = 0.09                0 : 1      =      1.5 : 1.0\n",
      "               avg_tfidf = 0.1                 1 : 0      =      1.4 : 1.0\n",
      "               avg_tfidf = 0.08                0 : 1      =      1.3 : 1.0\n",
      "               avg_tfidf = 0.03                1 : 0      =      1.3 : 1.0\n",
      "               avg_tfidf = 0.07                0 : 1      =      1.2 : 1.0\n",
      "               avg_tfidf = 0.04                0 : 1      =      1.2 : 1.0\n",
      "               avg_tfidf = 0.05                1 : 0      =      1.2 : 1.0\n",
      "               avg_tfidf = 0.06                1 : 0      =      1.1 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#train model and test accuracy for air 1 0.86\n",
    "classifier=nltk.NaiveBayesClassifier.train(training_set1)\n",
    "print(nltk.classify.accuracy(classifier,testing_set1)) \n",
    "print(classifier.show_most_informative_features(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureset2=[]#take few minutes\n",
    "for review_index in range(0,854):\n",
    "    clas=air2[review_index][1]\n",
    "    feature=tfidf_feature(review_index,air2_reviews,tfidf2,num_word2)\n",
    "    featureset2.append((feature,clas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "683\n",
      "171\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(featureset2)\n",
    "training_set2=featureset2[:int(len(featureset2)*0.8)] \n",
    "testing_set2=featureset2[int(len(featureset2)*0.8):]\n",
    "print(len(training_set2))\n",
    "print(len(testing_set2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5614035087719298\n",
      "Most Informative Features\n",
      "               avg_tfidf = 0.11                1 : 0      =      4.3 : 1.0\n",
      "               avg_tfidf = 0.03                0 : 1      =      2.5 : 1.0\n",
      "               avg_tfidf = 0.12                1 : 0      =      2.2 : 1.0\n",
      "               avg_tfidf = 0.05                0 : 1      =      1.9 : 1.0\n",
      "               avg_tfidf = 0.09                1 : 0      =      1.8 : 1.0\n",
      "               avg_tfidf = 0.1                 1 : 0      =      1.8 : 1.0\n",
      "               avg_tfidf = 0.15                1 : 0      =      1.7 : 1.0\n",
      "               avg_tfidf = 0.07                1 : 0      =      1.6 : 1.0\n",
      "               avg_tfidf = 0.13                1 : 0      =      1.6 : 1.0\n",
      "               avg_tfidf = 0.14                0 : 1      =      1.4 : 1.0\n",
      "               avg_tfidf = 0.04                0 : 1      =      1.3 : 1.0\n",
      "               avg_tfidf = 0.08                1 : 0      =      1.3 : 1.0\n",
      "               avg_tfidf = 0.06                0 : 1      =      1.1 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#train model and test accuracy for air 2 0.56\n",
    "classifier=nltk.NaiveBayesClassifier.train(training_set2)\n",
    "print(nltk.classify.accuracy(classifier,testing_set2)) \n",
    "print(classifier.show_most_informative_features(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureset3=[]#take few minutes\n",
    "for review_index in range(0,802):\n",
    "    clas=air3[review_index][1]\n",
    "    feature=tfidf_feature(review_index,air3_reviews,tfidf3,num_word3)\n",
    "    featureset3.append((feature,clas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "641\n",
      "161\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(featureset3)\n",
    "training_set3=featureset3[:int(len(featureset3)*0.8)] \n",
    "testing_set3=featureset3[int(len(featureset3)*0.8):]\n",
    "print(len(training_set3))\n",
    "print(len(testing_set3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.782608695652174\n",
      "Most Informative Features\n",
      "               avg_tfidf = 0.14                1 : 0      =      4.4 : 1.0\n",
      "               avg_tfidf = 0.11                1 : 0      =      4.1 : 1.0\n",
      "               avg_tfidf = 0.03                0 : 1      =      2.8 : 1.0\n",
      "               avg_tfidf = 0.17                1 : 0      =      2.7 : 1.0\n",
      "               avg_tfidf = 0.04                0 : 1      =      1.6 : 1.0\n",
      "               avg_tfidf = 0.1                 1 : 0      =      1.6 : 1.0\n",
      "               avg_tfidf = 0.13                0 : 1      =      1.4 : 1.0\n",
      "               avg_tfidf = 0.09                1 : 0      =      1.3 : 1.0\n",
      "               avg_tfidf = 0.06                1 : 0      =      1.2 : 1.0\n",
      "               avg_tfidf = 0.05                0 : 1      =      1.1 : 1.0\n",
      "               avg_tfidf = 0.07                1 : 0      =      1.1 : 1.0\n",
      "               avg_tfidf = 0.08                1 : 0      =      1.1 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#train model and test accuracy for air 3 0.78\n",
    "classifier=nltk.NaiveBayesClassifier.train(training_set3)\n",
    "print(nltk.classify.accuracy(classifier,testing_set3)) \n",
    "print(classifier.show_most_informative_features(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8652482269503546\n"
     ]
    }
   ],
   "source": [
    "#use decision tree(same accuracy result but no informative method) 0.86\n",
    "classifier=nltk.DecisionTreeClassifier.train(training_set1)\n",
    "print(nltk.classify.accuracy(classifier,testing_set1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5614035087719298\n"
     ]
    }
   ],
   "source": [
    "classifier=nltk.DecisionTreeClassifier.train(training_set2)0.56\n",
    "print(nltk.classify.accuracy(classifier,testing_set2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.782608695652174\n"
     ]
    }
   ],
   "source": [
    "classifier=nltk.DecisionTreeClassifier.train(training_set3)0.78\n",
    "print(nltk.classify.accuracy(classifier,testing_set3)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chunking (use most informative negative words )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#negative reviews for each airline\n",
    "air_canada_neg=[i[0] for i in lst1 if i[1]==0]# a list of neg reviews for air1\n",
    "air_canada_neg_review=''.join(air_canada_neg)\n",
    "british_airways_neg=[i[0] for i in lst2 if i[1]==0]# a list of neg reviews for air2\n",
    "british_airways_neg_review=''.join(british_airways_neg)\n",
    "united_airlines_neg=[i[0] for i in lst3 if i[1]==0]# a list of neg reviews for air3\n",
    "united_airlines_neg_review=''.join(united_airlines_neg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('uncomfortable flight', 17), ('uncomfortable seats', 14), ('seats were so uncomfortable', 6), ('seats were very uncomfortable', 4), ('seats are extremely uncomfortable', 3), ('seats are terribly uncomfortable', 3), ('seats are very uncomfortable', 3), ('seats were uncomfortable', 2), ('uncomfortable seating', 2), ('uncomfortable cramped', 2), ('uncomfortable seat', 2), ('uncomfortable lights', 1), ('uncomfortable trip', 1), ('Seating is uncomfortable', 1), ('Seats are uncomfortable', 1), ('uncomfortable outgoing', 1), ('uncomfortable ive', 1), ('uncomfortable way', 1), ('uncomfortable aircraft', 1), ('Rouge are very uncomfortable', 1), ('seat is uncomfortable', 1), ('seats were unbearably uncomfortable', 1), ('uncomfortable passenger', 1), ('flight was terribly uncomfortable', 1), ('Seats are horrendously uncomfortable', 1), ('seats are uncomfortable', 1), ('uncomfortable cabin', 1), ('uncomfortable seats.Rouge', 1), ('uncomfortable plane', 1), ('pitch was uncomfortable', 1)]\n"
     ]
    }
   ],
   "source": [
    "#chunking\n",
    "#for air1, most informative negative word is uncomfortable\n",
    "uncomfortable=[]\n",
    "text=air_canada_neg_review\n",
    "chunk='''\n",
    "NP: {<JJ.?><NN.*>}\n",
    "VP: {<NN.*><VB.?><RB>?<JJ.?>}\n",
    "'''\n",
    "parser=nltk.RegexpParser(chunk)\n",
    "pos=nltk.pos_tag(nltk.word_tokenize(text))\n",
    "tree=parser.parse(pos)\n",
    "for subtree in tree.subtrees():\n",
    "     if subtree.label()==\"NP\" and subtree.leaves()[0][0]==\"uncomfortable\":\n",
    "          uncomfortable.append(' '.join([w[0] for w in subtree.leaves()]))\n",
    "     if subtree.label()==\"VP\" and subtree.leaves()[-1][0]=='uncomfortable':\n",
    "          uncomfortable.append(' '.join([w[0] for w in subtree.leaves()]))\n",
    "uncomfortable_most_common=nltk.FreqDist(uncomfortable).most_common()\n",
    "print(uncomfortable_most_common)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('my knees touched the back', 3), ('my knees were touching the seat', 3), ('his knees hit the seat', 2), ('my knees touched the seat', 2), ('my knees hit the seat', 2), ('His knees were hitting the seat', 1), ('My knees were touching the back', 1), ('my knees were crushed against seat', 1), ('our knees straight in front', 1), ('my knees were hitting the seat', 1), ('his knees were touching the seat', 1), ('Your knees touch the seat', 1), ('my knees touching the seat', 1), ('my knees were pressed against seat', 1), ('my knees are touching the seat', 1), ('his knees touching the seat', 1)]\n"
     ]
    }
   ],
   "source": [
    "#chunking\n",
    "#for air1, another informative negative word is knees\n",
    "knees=[]\n",
    "text=air_canada_neg_review\n",
    "chunkstyle='chunk:{<PRP\\$><NN.*><VB.?>+<IN|DT><NN.*>}'\n",
    "\n",
    "parser=nltk.RegexpParser(chunkstyle)\n",
    "pos=nltk.pos_tag(nltk.word_tokenize(text))\n",
    "tree=parser.parse(pos)\n",
    "for subtree in tree.subtrees():\n",
    "    if subtree.label()==\"chunk\" and subtree.leaves()[1][0]==\"knees\":\n",
    "        knees.append(' '.join([w[0] for w in subtree.leaves()]))\n",
    "knees_most_common=nltk.FreqDist(knees).most_common()\n",
    "print(knees_most_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('uncomfortable seats', 4), ('awful food', 3), ('uncomfortable flight', 2), ('uncomfortable seat', 2), ('terrible experience', 1), ('terrible heat', 1), ('awful thank', 1), ('awful selection', 1), ('terrible picture', 1), ('disappointed quality', 1), ('uncomfortable blankets', 1), ('uncomfortable economy', 1), ('uncomfortable flights', 1), ('terrible service', 1), ('terrible reflection', 1), ('awful business', 1), ('terrible crew', 1), ('awful dirty', 1), ('awful service', 1), ('awful flight', 1), ('terrible -I', 1), ('awful breakfast', 1)]\n"
     ]
    }
   ],
   "source": [
    "#air 2 chunking for most informative negative words\n",
    "lst=['awful','terrible','uncomfortable','disappointed']\n",
    "text=british_airways_neg_review\n",
    "air2=[]\n",
    "chunk='''\n",
    "NP: {<JJ.?><NN.*>}\n",
    "VP: {<NN.*><VB.?><RB>?<JJ.?>}\n",
    "'''\n",
    "parser=nltk.RegexpParser(chunk)\n",
    "pos=nltk.pos_tag(nltk.word_tokenize(text))\n",
    "tree=parser.parse(pos)\n",
    "for subtree in tree.subtrees():\n",
    "    if subtree.label()==\"NP\" and subtree.leaves()[0][0] in lst:\n",
    "          air2.append(' '.join([w[0] for w in subtree.leaves()]))        \n",
    "    if subtree.label()==\"vP\" and subtree.leaves()[-1][0] in lst:\n",
    "          air2.append(' '.join([w[0] for w in subtree.leaves()]))\n",
    "    freq2=nltk.FreqDist(air2).most_common()\n",
    "print(freq2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('worst airline', 11), ('worst experience', 8), ('worst service', 6), ('worst flight', 5), ('worst part', 5), ('terrible airline', 4), ('worst customer', 4), ('worst travel', 4), ('wrong flight', 3), ('terrible flight', 2), ('terrible customer', 2), ('terrible experience', 2), ('wrong line', 2), ('worst food', 2), ('worst airlines', 2), ('rude flight', 2), ('wrong plane', 2), ('terrible food', 2), ('worst trip', 2), ('rude staff', 2), ('rude gate', 1), ('worst picture', 1), ('terrible seat', 1), ('terrible service', 1), ('rude attendants', 1), ('worst carriers', 1), ('rude Continental', 1), ('worst thing', 1), ('rude stewards', 1), ('rude flights', 1), ('terrible baggage', 1), ('terrible disruptions', 1), ('terrible seats.DEN', 1), ('wrong crew', 1), ('terrible seats', 1), ('rude service', 1), ('terrible disregard', 1), ('worst cappuccino', 1), ('wrong information', 1), ('terrible attitude', 1), ('rude employee', 1), ('wrong allocation', 1)]\n"
     ]
    }
   ],
   "source": [
    "#air 3 chunking for most informative negative words 'worst'\n",
    "lst=['worst','terrible','rude','wrong']\n",
    "text=united_airlines_neg_review\n",
    "air3=[]\n",
    "chunk='''\n",
    "NP: {<JJ.?><NN.*>}\n",
    "VP: {<NN.*><VB.?><RB>?<JJ.?>}\n",
    "'''\n",
    "parser=nltk.RegexpParser(chunk)\n",
    "pos=nltk.pos_tag(nltk.word_tokenize(text))\n",
    "tree=parser.parse(pos)\n",
    "for subtree in tree.subtrees():\n",
    "    if subtree.label()==\"NP\" and subtree.leaves()[0][0] in lst:\n",
    "          air3.append(' '.join([w[0] for w in subtree.leaves()]))        \n",
    "    if subtree.label()==\"vP\" and subtree.leaves()[-1][0] in lst:\n",
    "          air3.append(' '.join([w[0] for w in subtree.leaves()]))\n",
    "\n",
    "freq3=nltk.FreqDist(air3).most_common()\n",
    "print(freq3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('poor service', 12), ('poor customer', 9), ('worst service', 6), ('horrible service', 5), ('worst customer', 4), ('inflight service', 3), ('better service', 3), ('Terrible service', 3), ('terrible customer', 2), ('bad service', 2), ('good customer', 2), ('meal service', 2), ('awful customer', 2), ('lousy service', 2), ('minor service', 2), ('drink service', 1), ('friendly service', 1), ('enthusiastic service', 1), ('international service', 1), ('choice.Terrible service', 1), ('in-flight service', 1), ('horrible customer', 1), ('Horrible customer', 1), ('terrible service', 1), ('delays service', 1), ('on-board service', 1), ('acceptable service', 1), ('robotic service', 1), ('domestic service', 1), ('limited service', 1), ('In-flight service', 1), ('further service', 1), ('good service', 1), ('airline-poor customer', 1), ('full service', 1), ('nice service', 1), ('proper service', 1), ('marginal.Horrible customer', 1), ('upgraded service', 1), ('minimal service', 1), ('awful service', 1), ('individual customer', 1), ('Minimal service', 1), ('great customer', 1), ('dissatisfied customer', 1), ('superior service', 1), ('Horrible service', 1), ('adequate service', 1), ('nice customer', 1), ('massive customer', 1), ('video service', 1), ('great service', 1), ('pathetic customer', 1), ('decent service', 1), ('drinks service', 1), ('decent customer', 1), ('bad customer', 1), ('Swiss service', 1), ('end.Horrible service', 1), ('first customer', 1), ('outstanding service', 1), ('understaffed customer', 1), ('rude service', 1), ('uninspiring service', 1), ('different customer', 1), ('be.Terrible service', 1), ('unhelpful service', 1), ('new customer', 1), ('inept customer', 1), ('excellent service', 1)]\n"
     ]
    }
   ],
   "source": [
    "#air 3 chunking for most informative negative words 'worst'\n",
    "lst=['service','customer']\n",
    "text=united_airlines_neg_review\n",
    "air3=[]\n",
    "chunk='''\n",
    "NP: {<JJ.?><NN.*>}\n",
    "VP: {<NN.*><VB.?><RB>?<JJ.?>}\n",
    "'''\n",
    "parser=nltk.RegexpParser(chunk)\n",
    "pos=nltk.pos_tag(nltk.word_tokenize(text))\n",
    "tree=parser.parse(pos)\n",
    "for subtree in tree.subtrees():\n",
    "    if subtree.label()==\"NP\" and subtree.leaves()[-1][0] in lst:\n",
    "          air3.append(' '.join([w[0] for w in subtree.leaves()]))        \n",
    "    if subtree.label()==\"vP\" and subtree.leaves()[0][0] in lst:\n",
    "          air3.append(' '.join([w[0] for w in subtree.leaves()]))\n",
    "\n",
    "freq3=nltk.FreqDist(air3).most_common()\n",
    "print(freq3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
